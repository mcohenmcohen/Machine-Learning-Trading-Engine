###################################################################################################
# Trading System replication:
#
###################################################################################################
import numpy as np
from sklearn.preprocessing import Imputer
import inspect
import talib
from stock_system.TradingSystem import TradingSystem
from stock_system import TA, ModelUtils


class TradingSystem_Comp(TradingSystem):
    '''
    Parent class for trading systems
    '''
    def __init__(self):
        TradingSystem.__init__(self)
        self.df = None  # The source data frame - the X features
        self.target = None  # The y label target, generated by a system algorithm from X data
        self.features = []  # list of X feature columns for the trading system and implementing model

    def preprocess_data(self, data):
        '''
        Perform any data preprocessing steps such as normalizing, smoothing,
        remove correlated columns, etc
        '''
        df = data.copy()

        #df = TA.run_techicals(df)

        # normal and smoothed Price series
        # opn = df['open']
        # high = df['high']
        # low = df['low']
        # close = df['close']
        opn = df['open'].ewm(com=.8).mean()
        high = df['high'].ewm(com=.8).mean()
        low = df['low'].ewm(com=.8).mean()
        close = df['close'].ewm(com=.8).mean()
        volume = df['volume'].astype(float)
        # df['log_close'] = np.log(close)
        # df = TA.run_exp_smooth(df, alpha=.5)
        # opn_sm = df['exp_smooth_open']
        # high_sm = df['exp_smooth_high']
        # low_sm = df['exp_smooth_low']
        # close_sm = df['exp_smooth_close']
        # volume_sm = df['exp_smooth_volume']
        mean_log_close_5 = np.log(close.rolling(window=5).mean())
        df['apc5'] = mean_log_close_5 / talib.ATR(high.values, low.values, np.log(close).values, timeperiod=100)

        # from article post
        #import pdb; pdb.set_trace()
        daily_return = close - close.shift(1)  # today - yesterday close
        daily_return[np.isnan(daily_return)] = 0
        df['log_daily_return'] = np.log(daily_return + 1 - min(daily_return))
        # daily_p = history(bar_count=100, frequency='1d', field='price')
        # daily_ret = daily_p.pct_change()
        # daily_log = np.log1p(daily_ret)
        # daily_log_mean = pd.rolling_mean(daily_log, 5)
        # print daily_log_mean.tail(5)

        # df['atr14'] = talib.ATR(high.values, low.values, close.values, timeperiod=14)
        df['ATRrat3'] = talib.ATR(high.values, low.values, close.values, timeperiod=3) / talib.ATR(high.values, low.values, close.values, timeperiod=21)
        # df['ATRrat1050'] = talib.ATR(high.values, low.values, close.values, timeperiod=10) / talib.ATR(high.values, low.values, close.values, timeperiod=50)
        df['deltaATRrat33'] = df['ATRrat3'] - np.roll(df['ATRrat3'], 3)
        #df['deltaATRrat310'] = df['ATRrat3'] - np.roll(df['ATRrat3'], 10)
        upperband, middleband, lowerband = talib.BBANDS(close.values, timeperiod=3, nbdevup=2, nbdevdn=2, matype=0)
        df['bWidth3'] = upperband - lowerband
        upperband, middleband, lowerband = talib.BBANDS(close.values, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)
        df['bWidth20'] = upperband - lowerband
        df['deltabWidth33'] = df['bWidth3'] - np.roll(df['bWidth3'], 3)
        df['deltabWidth310'] = df['bWidth3'] - np.roll(df['bWidth3'], 10)

        df['price_var_ratio'] = df.close.rolling(window=10).var() / df.close.rolling(window=30).var()
        df['deltaPVR5'] = df['price_var_ratio'] - np.roll(df['price_var_ratio'], 5)
        #df['hurst'] = TA.hurst(close)
        df['willr'] = talib.WILLR(high.values, low.values, close.values, timeperiod=14)
        df['obv'] = talib.OBV(close.values, volume.values)
        stok, df['stod'] = talib.STOCH(high.values, low.values, close.values, fastk_period=5, slowk_period=3,
                                             slowk_matype=0, slowd_period=3, slowd_matype=0)
        df['deltabWidth310'] = df['bWidth3'] - np.roll(df['bWidth3'], 10)
        df['atr7'] = talib.ATR(high.values, low.values, close.values, timeperiod=7)
        df['ATRrat1020'] = talib.ATR(high.values, low.values, close.values, timeperiod=10) / talib.ATR(high.values, low.values, close.values, timeperiod=20)
        df['ATRrat10100'] = talib.ATR(high.values, low.values, close.values, timeperiod=10) / talib.ATR(high.values, low.values, close.values, timeperiod=100)

        # Normalize all columns above but these defaulta:
        cols = [col for col in df.columns if col not in self.excluded_features]
        def max_min_normalize(ndarr):
            x = (ndarr - ndarr.min())/( ndarr.max()-ndarr.min())
            return x[-1]
        for col in cols:
            df[col] = df[col].rolling(window=50).apply(max_min_normalize)

        # Non-normalized columns
        # stats
        df['roc1'] = TA.rate_of_change(close, 1)  # highly correlated with daily returns
        df['roc2'] = TA.rate_of_change(close, 2)
        df['roc5'] = TA.rate_of_change(close, 5)
        df['slope20'] = df['close'].rolling(window=20).apply(TA.slope_calc)
        df['velocity'] = df['close'] + (df['slope20'] * df['close']) / 20
        df['stdClose20'] = df['close'].shift(1).rolling(window=20).std()
        df['zscore'] = (df['close'] - df['close'].shift(1).rolling(window=20).mean()) / df['stdClose20']
        # Oscilattors are by design already normalized
        df['mom3'] = talib.MOM(close.values, timeperiod=3)
        df['mom10'] = talib.MOM(close.values, timeperiod=10)  # 2 week momentum
        df['mom20'] = talib.MOM(close.values, timeperiod=20)  # 4 week momentum
        df['mom10accel'] = df['mom10'] - df['mom10'].shift(4)  # 4 days diff
        df['mom20accel'] = df['mom20'] - df['mom20'].shift(4)  # 4 days diff
        # Price extremes
        df['HH20'] = (df['high'] > df['high'].shift(1).rolling(window=20).max()).astype(int)  # highest high in 4 weeks
        df['HH5'] = (df['high'] > df['high'].shift(1).rolling(window=5).max()).astype(int)  # highest high in 1 week
        df['LL20'] = (df['low'] < df['low'].shift(1).rolling(window=20).min()).astype(int)  # highest high in 4 weeks
        df['LL5'] = (df['low'] < df['low'].shift(1).rolling(window=5).min()).astype(int)  # highest high in 1 week
        # Candle and volume Size
        vol30 = df['volume'].shift(1).rolling(window=30).mean()
        relVolSize = df['volume'] / vol30
        relVolSize[np.isnan(relVolSize)] = 0  # impute inf to 0
        df['relVolSize'] = relVolSize
        cSize = (df['close'] - df['open']).abs()
        cSize30 = cSize.shift(1).rolling(window=30).mean()
        relCanSize = cSize / cSize30
        relCanSize[np.isnan(relCanSize)] = 0  # impute inf to 0
        df['relCanSize'] = relCanSize
        # MAs
        df['sma5'] = talib.SMA(df['close'].values, 5)
        df['sma20'] = talib.SMA(df['close'].values, 20)
        df['sma50'] = talib.SMA(df['close'].values, 50)
        # MA discrete series
        # df['MACurOver3'] = (df['close'] > df['close'].shift(1).rolling(window=3).mean()).astype(int)
        # df['MA3Over5'] = (df['close'].rolling(window=3).mean() > df['close'].shift(1).rolling(window=5).mean()).astype(int)
        # df['MA5Over10'] = (df['close'].rolling(window=5).mean() > df['close'].shift(1).rolling(window=10).mean()).astype(int)
        # df['MA5ver20'] = (df['close'].rolling(window=5).mean() > df['close'].shift(1).rolling(window=20).mean()).astype(int)
        # Last n days
        df['twoDownDays'] = ((df['close'] < df['close'].shift(1)) & (df['close'].shift(1) < df['close'].shift(2))).astype(int)
        df['threeDownDays'] = ((df['close'] < df['close'].shift(1)) & (df['close'].shift(1) < df['close'].shift(2)) & (df['close'].shift(2) < df['close'].shift(3))).astype(int)

        # Impute - delete rows with Nan and null.  Will be the first several rows
        imp = Imputer(missing_values='NaN', strategy='mean', axis=0)
        #imp = imp.fit(X_train)
        for name in df.columns:
            df = df[df[name].notnull()]


        self.df = df

        return self.df


    def get_features(self):
        ### For SPY ###
        # Oscilators
        # x_osc = ['rsi', 'cci', 'stod', 'stok', 'willr']
        # x_oscd_cols = ['rsi_d', 'cci_d', 'stod_d', 'stok_d', 'willr_d']
        # # MAs
        # x_ma_cols = ['sma20', 'sma50', 'sma200', 'wma10', 'macd_d']
        # x_all_dscrete_cols = ['roc_d', 'rsi_d', 'cci_d', 'stod_d', 'stok_d', 'willr_d', 'mom_d']
        # #x_cols = ['roc', 'rsi', 'willr', 'obv', 'stok']#'mom', , 'cci',  'stod', 'macd', 'sma', 'sma50', 'wma']
        # #x_cols = ['roc']
        # x_cols = x_all_dscrete_cols + x_ma_cols
        return self.features

    def set_features(self, features):
        '''
        Set the features for the tradng system to be used by the model

        input:  list of features, column names
        '''
        self.features = features

    def feature_forensics(self, model):
        return TradingSystem.feature_forensics(self, model)

    def generate_target(self):
        '''
        Trading system goes here.
        This runs the trading system on the training data to generate the y label.

        **** CAVEAT ****
        If target is price change over n days, you need to shift the y label target
        by n days (at least one day) to ensure no future leak.

        Returns a dataframe with the y label column, ready to use in a model for fit and predict.
        '''
        if self.df is None:
            print 'This trading system has no data.  Call preprocess_data first.'
            return

        # Target is a one-day price change
        days_ahead = -1
        gain_loss = np.roll(self.df['close'], days_ahead) - self.df['close']
        self.df['y_true'] = (gain_loss >= 0).astype(int)

        # Drop the last row becaue of the shift by 1 - it puts the first to the last
        # Probably needs to change
        self.df = self.df[:-1]

        return self.df
